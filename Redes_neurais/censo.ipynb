{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rede neural - Census.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('../PKLs/census.pkl', 'rb') as f:\n",
    "    X_census_treinamento, y_census_treinamento, X_census_teste, y_census_teste = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((27676, 108), (27676,))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_census_treinamento.shape, y_census_treinamento.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "rede_neural_census = MLPClassifier(verbose=True, max_iter=1000, tol=0.000010, hidden_layer_sizes= (55,55), activation='relu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.39430184\n",
      "Iteration 2, loss = 0.32726787\n",
      "Iteration 3, loss = 0.31551542\n",
      "Iteration 4, loss = 0.30842500\n",
      "Iteration 5, loss = 0.30344044\n",
      "Iteration 6, loss = 0.29938721\n",
      "Iteration 7, loss = 0.29632344\n",
      "Iteration 8, loss = 0.29422616\n",
      "Iteration 9, loss = 0.29078974\n",
      "Iteration 10, loss = 0.28955165\n",
      "Iteration 11, loss = 0.28701377\n",
      "Iteration 12, loss = 0.28527809\n",
      "Iteration 13, loss = 0.28352889\n",
      "Iteration 14, loss = 0.28173953\n",
      "Iteration 15, loss = 0.28027929\n",
      "Iteration 16, loss = 0.27802378\n",
      "Iteration 17, loss = 0.27713820\n",
      "Iteration 18, loss = 0.27576684\n",
      "Iteration 19, loss = 0.27332574\n",
      "Iteration 20, loss = 0.27206315\n",
      "Iteration 21, loss = 0.27008392\n",
      "Iteration 22, loss = 0.26939561\n",
      "Iteration 23, loss = 0.26775612\n",
      "Iteration 24, loss = 0.26576674\n",
      "Iteration 25, loss = 0.26454500\n",
      "Iteration 26, loss = 0.26344732\n",
      "Iteration 27, loss = 0.26120939\n",
      "Iteration 28, loss = 0.26105857\n",
      "Iteration 29, loss = 0.26006900\n",
      "Iteration 30, loss = 0.25774733\n",
      "Iteration 31, loss = 0.25570558\n",
      "Iteration 32, loss = 0.25544046\n",
      "Iteration 33, loss = 0.25376855\n",
      "Iteration 34, loss = 0.25290879\n",
      "Iteration 35, loss = 0.25222078\n",
      "Iteration 36, loss = 0.25052786\n",
      "Iteration 37, loss = 0.24915313\n",
      "Iteration 38, loss = 0.24804782\n",
      "Iteration 39, loss = 0.24612935\n",
      "Iteration 40, loss = 0.24710764\n",
      "Iteration 41, loss = 0.24456237\n",
      "Iteration 42, loss = 0.24350977\n",
      "Iteration 43, loss = 0.24223545\n",
      "Iteration 44, loss = 0.24087070\n",
      "Iteration 45, loss = 0.23938611\n",
      "Iteration 46, loss = 0.23943061\n",
      "Iteration 47, loss = 0.23761452\n",
      "Iteration 48, loss = 0.23733594\n",
      "Iteration 49, loss = 0.23617520\n",
      "Iteration 50, loss = 0.23579556\n",
      "Iteration 51, loss = 0.23511529\n",
      "Iteration 52, loss = 0.23520814\n",
      "Iteration 53, loss = 0.23219878\n",
      "Iteration 54, loss = 0.23206762\n",
      "Iteration 55, loss = 0.22949783\n",
      "Iteration 56, loss = 0.22959348\n",
      "Iteration 57, loss = 0.22892968\n",
      "Iteration 58, loss = 0.22820457\n",
      "Iteration 59, loss = 0.22614003\n",
      "Iteration 60, loss = 0.22675012\n",
      "Iteration 61, loss = 0.22534520\n",
      "Iteration 62, loss = 0.22485976\n",
      "Iteration 63, loss = 0.22314984\n",
      "Iteration 64, loss = 0.22344787\n",
      "Iteration 65, loss = 0.22190278\n",
      "Iteration 66, loss = 0.22052121\n",
      "Iteration 67, loss = 0.22005269\n",
      "Iteration 68, loss = 0.21922904\n",
      "Iteration 69, loss = 0.21943679\n",
      "Iteration 70, loss = 0.21842052\n",
      "Iteration 71, loss = 0.21656948\n",
      "Iteration 72, loss = 0.21587141\n",
      "Iteration 73, loss = 0.21681876\n",
      "Iteration 74, loss = 0.21425251\n",
      "Iteration 75, loss = 0.21403109\n",
      "Iteration 76, loss = 0.21389082\n",
      "Iteration 77, loss = 0.21302199\n",
      "Iteration 78, loss = 0.21221243\n",
      "Iteration 79, loss = 0.21151402\n",
      "Iteration 80, loss = 0.21040507\n",
      "Iteration 81, loss = 0.20925718\n",
      "Iteration 82, loss = 0.20910384\n",
      "Iteration 83, loss = 0.20848204\n",
      "Iteration 84, loss = 0.20772330\n",
      "Iteration 85, loss = 0.20795287\n",
      "Iteration 86, loss = 0.20700443\n",
      "Iteration 87, loss = 0.20654174\n",
      "Iteration 88, loss = 0.20629879\n",
      "Iteration 89, loss = 0.20537107\n",
      "Iteration 90, loss = 0.20556032\n",
      "Iteration 91, loss = 0.20493073\n",
      "Iteration 92, loss = 0.20487516\n",
      "Iteration 93, loss = 0.20393784\n",
      "Iteration 94, loss = 0.20227976\n",
      "Iteration 95, loss = 0.20204876\n",
      "Iteration 96, loss = 0.20106145\n",
      "Iteration 97, loss = 0.20159475\n",
      "Iteration 98, loss = 0.19980932\n",
      "Iteration 99, loss = 0.19936665\n",
      "Iteration 100, loss = 0.19945461\n",
      "Iteration 101, loss = 0.19831813\n",
      "Iteration 102, loss = 0.19764472\n",
      "Iteration 103, loss = 0.19739002\n",
      "Iteration 104, loss = 0.19845162\n",
      "Iteration 105, loss = 0.19708335\n",
      "Iteration 106, loss = 0.19678298\n",
      "Iteration 107, loss = 0.19484063\n",
      "Iteration 108, loss = 0.19598827\n",
      "Iteration 109, loss = 0.19590432\n",
      "Iteration 110, loss = 0.19528404\n",
      "Iteration 111, loss = 0.19485640\n",
      "Iteration 112, loss = 0.19560209\n",
      "Iteration 113, loss = 0.19441899\n",
      "Iteration 114, loss = 0.19257451\n",
      "Iteration 115, loss = 0.19232146\n",
      "Iteration 116, loss = 0.19167488\n",
      "Iteration 117, loss = 0.19239497\n",
      "Iteration 118, loss = 0.19116089\n",
      "Iteration 119, loss = 0.19054200\n",
      "Iteration 120, loss = 0.18924209\n",
      "Iteration 121, loss = 0.19005496\n",
      "Iteration 122, loss = 0.19041935\n",
      "Iteration 123, loss = 0.18963460\n",
      "Iteration 124, loss = 0.18947345\n",
      "Iteration 125, loss = 0.18862068\n",
      "Iteration 126, loss = 0.18807159\n",
      "Iteration 127, loss = 0.18682450\n",
      "Iteration 128, loss = 0.18727012\n",
      "Iteration 129, loss = 0.18905974\n",
      "Iteration 130, loss = 0.18731954\n",
      "Iteration 131, loss = 0.18645376\n",
      "Iteration 132, loss = 0.18516142\n",
      "Iteration 133, loss = 0.18638215\n",
      "Iteration 134, loss = 0.18553241\n",
      "Iteration 135, loss = 0.18519244\n",
      "Iteration 136, loss = 0.18443048\n",
      "Iteration 137, loss = 0.18358162\n",
      "Iteration 138, loss = 0.18283855\n",
      "Iteration 139, loss = 0.18248849\n",
      "Iteration 140, loss = 0.18355321\n",
      "Iteration 141, loss = 0.18410653\n",
      "Iteration 142, loss = 0.18308080\n",
      "Iteration 143, loss = 0.18179014\n",
      "Iteration 144, loss = 0.18104917\n",
      "Iteration 145, loss = 0.18062558\n",
      "Iteration 146, loss = 0.18133764\n",
      "Iteration 147, loss = 0.18064401\n",
      "Iteration 148, loss = 0.18106165\n",
      "Iteration 149, loss = 0.18018965\n",
      "Iteration 150, loss = 0.17962729\n",
      "Iteration 151, loss = 0.17942663\n",
      "Iteration 152, loss = 0.17896649\n",
      "Iteration 153, loss = 0.17905702\n",
      "Iteration 154, loss = 0.17820194\n",
      "Iteration 155, loss = 0.17870082\n",
      "Iteration 156, loss = 0.17732377\n",
      "Iteration 157, loss = 0.17781096\n",
      "Iteration 158, loss = 0.17733198\n",
      "Iteration 159, loss = 0.17782933\n",
      "Iteration 160, loss = 0.17639741\n",
      "Iteration 161, loss = 0.17715589\n",
      "Iteration 162, loss = 0.17645610\n",
      "Iteration 163, loss = 0.17523858\n",
      "Iteration 164, loss = 0.17517431\n",
      "Iteration 165, loss = 0.17620379\n",
      "Iteration 166, loss = 0.17570536\n",
      "Iteration 167, loss = 0.17438454\n",
      "Iteration 168, loss = 0.17393910\n",
      "Iteration 169, loss = 0.17346892\n",
      "Iteration 170, loss = 0.17356912\n",
      "Iteration 171, loss = 0.17450861\n",
      "Iteration 172, loss = 0.17414762\n",
      "Iteration 173, loss = 0.17408019\n",
      "Iteration 174, loss = 0.17323823\n",
      "Iteration 175, loss = 0.17413712\n",
      "Iteration 176, loss = 0.17376742\n",
      "Iteration 177, loss = 0.17211421\n",
      "Iteration 178, loss = 0.17282741\n",
      "Iteration 179, loss = 0.17211065\n",
      "Iteration 180, loss = 0.17200885\n",
      "Iteration 181, loss = 0.17202038\n",
      "Iteration 182, loss = 0.17107117\n",
      "Iteration 183, loss = 0.17227452\n",
      "Iteration 184, loss = 0.17012671\n",
      "Iteration 185, loss = 0.17191643\n",
      "Iteration 186, loss = 0.17048838\n",
      "Iteration 187, loss = 0.17100426\n",
      "Iteration 188, loss = 0.16907758\n",
      "Iteration 189, loss = 0.17037028\n",
      "Iteration 190, loss = 0.16995876\n",
      "Iteration 191, loss = 0.16859954\n",
      "Iteration 192, loss = 0.16799405\n",
      "Iteration 193, loss = 0.16889936\n",
      "Iteration 194, loss = 0.16772740\n",
      "Iteration 195, loss = 0.16814343\n",
      "Iteration 196, loss = 0.16724474\n",
      "Iteration 197, loss = 0.16717046\n",
      "Iteration 198, loss = 0.16809071\n",
      "Iteration 199, loss = 0.16711688\n",
      "Iteration 200, loss = 0.16819849\n",
      "Iteration 201, loss = 0.16745952\n",
      "Iteration 202, loss = 0.16600254\n",
      "Iteration 203, loss = 0.16623535\n",
      "Iteration 204, loss = 0.16615617\n",
      "Iteration 205, loss = 0.16615406\n",
      "Iteration 206, loss = 0.16539670\n",
      "Iteration 207, loss = 0.16599736\n",
      "Iteration 208, loss = 0.16428505\n",
      "Iteration 209, loss = 0.16404384\n",
      "Iteration 210, loss = 0.16481935\n",
      "Iteration 211, loss = 0.16441458\n",
      "Iteration 212, loss = 0.16402379\n",
      "Iteration 213, loss = 0.16502248\n",
      "Iteration 214, loss = 0.16541072\n",
      "Iteration 215, loss = 0.16430448\n",
      "Iteration 216, loss = 0.16278475\n",
      "Iteration 217, loss = 0.16412071\n",
      "Iteration 218, loss = 0.16266056\n",
      "Iteration 219, loss = 0.16339522\n",
      "Iteration 220, loss = 0.16245180\n",
      "Iteration 221, loss = 0.16508211\n",
      "Iteration 222, loss = 0.16189725\n",
      "Iteration 223, loss = 0.16365936\n",
      "Iteration 224, loss = 0.16276187\n",
      "Iteration 225, loss = 0.16140575\n",
      "Iteration 226, loss = 0.16172305\n",
      "Iteration 227, loss = 0.16034277\n",
      "Iteration 228, loss = 0.16171790\n",
      "Iteration 229, loss = 0.16128270\n",
      "Iteration 230, loss = 0.16099626\n",
      "Iteration 231, loss = 0.16035663\n",
      "Iteration 232, loss = 0.15979624\n",
      "Iteration 233, loss = 0.16104882\n",
      "Iteration 234, loss = 0.15970741\n",
      "Iteration 235, loss = 0.16039499\n",
      "Iteration 236, loss = 0.15987556\n",
      "Iteration 237, loss = 0.15877406\n",
      "Iteration 238, loss = 0.15855194\n",
      "Iteration 239, loss = 0.15842170\n",
      "Iteration 240, loss = 0.15964690\n",
      "Iteration 241, loss = 0.16012762\n",
      "Iteration 242, loss = 0.15870054\n",
      "Iteration 243, loss = 0.15774693\n",
      "Iteration 244, loss = 0.15753773\n",
      "Iteration 245, loss = 0.15874744\n",
      "Iteration 246, loss = 0.15906297\n",
      "Iteration 247, loss = 0.15910688\n",
      "Iteration 248, loss = 0.15792802\n",
      "Iteration 249, loss = 0.15695025\n",
      "Iteration 250, loss = 0.15745038\n",
      "Iteration 251, loss = 0.15640327\n",
      "Iteration 252, loss = 0.15816385\n",
      "Iteration 253, loss = 0.15634029\n",
      "Iteration 254, loss = 0.15945045\n",
      "Iteration 255, loss = 0.15616060\n",
      "Iteration 256, loss = 0.15608074\n",
      "Iteration 257, loss = 0.15613401\n",
      "Iteration 258, loss = 0.15602452\n",
      "Iteration 259, loss = 0.15595851\n",
      "Iteration 260, loss = 0.15548973\n",
      "Iteration 261, loss = 0.15486177\n",
      "Iteration 262, loss = 0.15456235\n",
      "Iteration 263, loss = 0.15451592\n",
      "Iteration 264, loss = 0.15434491\n",
      "Iteration 265, loss = 0.15520051\n",
      "Iteration 266, loss = 0.15522075\n",
      "Iteration 267, loss = 0.15583935\n",
      "Iteration 268, loss = 0.15756631\n",
      "Iteration 269, loss = 0.15558278\n",
      "Iteration 270, loss = 0.15239733\n",
      "Iteration 271, loss = 0.15443714\n",
      "Iteration 272, loss = 0.15481939\n",
      "Iteration 273, loss = 0.15455465\n",
      "Iteration 274, loss = 0.15507080\n",
      "Iteration 275, loss = 0.15273486\n",
      "Iteration 276, loss = 0.15241176\n",
      "Iteration 277, loss = 0.15256054\n",
      "Iteration 278, loss = 0.15138996\n",
      "Iteration 279, loss = 0.15075289\n",
      "Iteration 280, loss = 0.15225871\n",
      "Iteration 281, loss = 0.15295567\n",
      "Iteration 282, loss = 0.15081556\n",
      "Iteration 283, loss = 0.15131698\n",
      "Iteration 284, loss = 0.15100132\n",
      "Iteration 285, loss = 0.15126732\n",
      "Iteration 286, loss = 0.15060684\n",
      "Iteration 287, loss = 0.15179253\n",
      "Iteration 288, loss = 0.15100128\n",
      "Iteration 289, loss = 0.15203201\n",
      "Iteration 290, loss = 0.15201144\n",
      "Iteration 291, loss = 0.14929709\n",
      "Iteration 292, loss = 0.14994049\n",
      "Iteration 293, loss = 0.15044217\n",
      "Iteration 294, loss = 0.14941407\n",
      "Iteration 295, loss = 0.14997086\n",
      "Iteration 296, loss = 0.15056949\n",
      "Iteration 297, loss = 0.14923746\n",
      "Iteration 298, loss = 0.14978082\n",
      "Iteration 299, loss = 0.14905732\n",
      "Iteration 300, loss = 0.14907199\n",
      "Iteration 301, loss = 0.14940177\n",
      "Iteration 302, loss = 0.14896555\n",
      "Iteration 303, loss = 0.15036105\n",
      "Iteration 304, loss = 0.14912802\n",
      "Iteration 305, loss = 0.14772287\n",
      "Iteration 306, loss = 0.14775411\n",
      "Iteration 307, loss = 0.14822711\n",
      "Iteration 308, loss = 0.14983535\n",
      "Iteration 309, loss = 0.14866642\n",
      "Iteration 310, loss = 0.14979435\n",
      "Iteration 311, loss = 0.14982060\n",
      "Iteration 312, loss = 0.14756206\n",
      "Iteration 313, loss = 0.14661988\n",
      "Iteration 314, loss = 0.14786325\n",
      "Iteration 315, loss = 0.14851405\n",
      "Iteration 316, loss = 0.14623114\n",
      "Iteration 317, loss = 0.14857606\n",
      "Iteration 318, loss = 0.14625447\n",
      "Iteration 319, loss = 0.14692406\n",
      "Iteration 320, loss = 0.14692032\n",
      "Iteration 321, loss = 0.14404024\n",
      "Iteration 322, loss = 0.14425406\n",
      "Iteration 323, loss = 0.14517191\n",
      "Iteration 324, loss = 0.14553489\n",
      "Iteration 325, loss = 0.14811701\n",
      "Iteration 326, loss = 0.14648596\n",
      "Iteration 327, loss = 0.14378758\n",
      "Iteration 328, loss = 0.14615377\n",
      "Iteration 329, loss = 0.14496636\n",
      "Iteration 330, loss = 0.14525084\n",
      "Iteration 331, loss = 0.14632830\n",
      "Iteration 332, loss = 0.14487892\n",
      "Iteration 333, loss = 0.14344069\n",
      "Iteration 334, loss = 0.14387231\n",
      "Iteration 335, loss = 0.14341336\n",
      "Iteration 336, loss = 0.14439282\n",
      "Iteration 337, loss = 0.14553441\n",
      "Iteration 338, loss = 0.14651294\n",
      "Iteration 339, loss = 0.14524004\n",
      "Iteration 340, loss = 0.14473111\n",
      "Iteration 341, loss = 0.14406210\n",
      "Iteration 342, loss = 0.14322235\n",
      "Iteration 343, loss = 0.14530938\n",
      "Iteration 344, loss = 0.14181373\n",
      "Iteration 345, loss = 0.14303467\n",
      "Iteration 346, loss = 0.14281158\n",
      "Iteration 347, loss = 0.14499174\n",
      "Iteration 348, loss = 0.14456577\n",
      "Iteration 349, loss = 0.14255550\n",
      "Iteration 350, loss = 0.14035185\n",
      "Iteration 351, loss = 0.14128547\n",
      "Iteration 352, loss = 0.14034569\n",
      "Iteration 353, loss = 0.14293539\n",
      "Iteration 354, loss = 0.14093631\n",
      "Iteration 355, loss = 0.14448473\n",
      "Iteration 356, loss = 0.14234086\n",
      "Iteration 357, loss = 0.14268892\n",
      "Iteration 358, loss = 0.14176876\n",
      "Iteration 359, loss = 0.14192551\n",
      "Iteration 360, loss = 0.14156246\n",
      "Iteration 361, loss = 0.14046502\n",
      "Training loss did not improve more than tol=0.000010 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPClassifier(hidden_layer_sizes=(55, 55), max_iter=1000, tol=1e-05,\n",
       "              verbose=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(hidden_layer_sizes=(55, 55), max_iter=1000, tol=1e-05,\n",
       "              verbose=True)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MLPClassifier(hidden_layer_sizes=(55, 55), max_iter=1000, tol=1e-05,\n",
       "              verbose=True)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rede_neural_census.fit(X_census_treinamento, y_census_treinamento)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acurácia\n",
    "\n",
    "Aqui deixou bastante a desejar, foi pior até que árvore de decisão!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8186284544524053"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "previsoes = rede_neural_census.predict(X_census_teste)\n",
    "\n",
    "accuracy_score(y_census_teste, previsoes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matriz de confusão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8186284544524053"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x550 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from yellowbrick.classifier import ConfusionMatrix\n",
    "cm = ConfusionMatrix(rede_neural_census)\n",
    "cm.fit(X_census_treinamento, y_census_treinamento)\n",
    "cm.score(X_census_teste, y_census_teste)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
